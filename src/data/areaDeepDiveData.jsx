// data/areaDeepDiveData.js

export const areaDeepDiveData = [

  // ðŸ”µ QUALITY (ID 1)
  { idArea: 1, comment: "The current Quality maturity is constrained primarily by fragmented data, a lack of standardization, and limited analytical depth, rather than by a lack of effort or the absence of processes." },
  { idArea: 1, comment: "Several Quality practices are in place and operating, particularly calibrations, feedback delivery, and governance routines. However, these practices are not yet supported by an integrated operating system capable of proving root cause or sustained performance impact." },
  { idArea: 1, comment: "Information required to manage Quality effectively is distributed across multiple disconnected Excel files. This requires manual consolidation and creates dependency on individuals rather than governed systems." },
  { idArea: 1, comment: "Monitoring maturity remains low due to the absence of repeatable coverage planning, spot-check governance, and stable Quality-to-team ownership. This weakens accountability and consistency over time." },
  { idArea: 1, comment: "KPI and outlier management is largely descriptive, focused on averages and surface trends, with limited segmentation by parameter, tenure, individual, or category to enable targeted interventions." },
  { idArea: 1, comment: "Root cause discussions exist and are embedded in the workflow, but they are not consistently supported by data-backed analysis or connected to structured outlier identification and impact measurement." },
  { idArea: 1, comment: "As a result, Quality can identify issues and trends, but cannot consistently demonstrate causality, prioritize the highest-impact drivers, or measure whether corrective actions materially improved performance." },
  { idArea: 1, comment: "This places the Quality function in a controlled but fragile operating state, with maturity accurately assessed at approximately 62 percent." },

  // ðŸŸ¢ TRAINING (ID 2)
  { idArea: 2, comment: "Training has a stable execution baseline that allows interpreter onboarding and waves to run consistently." },
  { idArea: 2, comment: "The overall maturity score of 51.6% is driven primarily by curriculum structure, content delivery, and class-level execution controls." },
  { idArea: 2, comment: "Training strategy is not defined at a wave or interpreter-profile level, limiting the ability to proactively address differences in language complexity, specialization, or expected call mix." },
  { idArea: 2, comment: "Learning effectiveness and readiness are not formally measured beyond completion and satisfaction, creating limited visibility into time-to-independence and early tenure risk." },
  { idArea: 2, comment: "Nesting and graduation transitions are executed operationally but are not governed end-to-end by Training, reducing control over readiness leakage into production." },
  { idArea: 2, comment: "Training analytics are not consolidated to provide Operations with a clear, real-time view of how each wave is progressing in terms of readiness, risk, and graduation likelihood." },
  { idArea: 2, comment: "Continuous upskilling beyond initial training is largely reactive and not structured as part of a longer-term interpreter development model." },
  { idArea: 2, comment: "Incentive and bonus structures are not clearly aligned to readiness, quality stability, or sustained interpreter performance." },
  { idArea: 2, comment: "As a result, Training delivers waves reliably, but has limited leverage over graduation quality, early tenure outcomes, and downstream operational performance." },

  // ðŸŸ¡ WORKFORCE (ID 3)
  { idArea: 3, comment: "The current Workforce Management maturity is constrained primarily by data structure and planning visibility gaps, not by a clearly identified execution failure." },
  { idArea: 3, comment: "The sub-categories with the highest impact and largest opportunity are Forecasting, Contract & Commercial Governance, Reporting & Insights, and Shrinkage & ABS, as reflected in the maturity scores." },
  { idArea: 3, comment: "There is no consolidated view that clearly shows how actual operational behavior compares against planning assumptions, limiting validation of assumptions." },
  { idArea: 3, comment: "The absence of variance analysis between forecast locks and weekly requirements limits proactive planning and structured client conversations." },
  { idArea: 3, comment: "Current real-time visibility constraints reduce accountability when managing sensitive metrics such as interval compliance." },
  { idArea: 3, comment: "There is no structured analysis of arrival patterns and demand distribution to identify curve smoothing opportunities." },
  { idArea: 3, comment: "The current forecast horizon is misaligned with hiring and onboarding lead times, increasing reactive staffing." },
  { idArea: 3, comment: "Staffing pressure is addressed primarily through short-term scheduling and intraday measures without sufficient upstream controls." },

  // ðŸŸ£ RECRUITMENT (ID 4)
  { idArea: 4, comment: "Recruitment maturity is limited primarily by reactive demand intake, incomplete data granularity, and weak closed-loop governance." },
  { idArea: 4, comment: "Leadership is consolidating toward a primary ATS, but parallel Excel trackers remain, creating data risk." },
  { idArea: 4, comment: "Hiring remains largely reactive, reducing anticipation of attrition and ramp needs." },
  { idArea: 4, comment: "City-level data is not captured, limiting geographic performance analysis." },
  { idArea: 4, comment: "Absence of requisitions per hiring wave prevents cohort-level analysis." },
  { idArea: 4, comment: "External recruitment governance remains informal." },
  { idArea: 4, comment: "Assessment outputs are not system-integrated for analytics use." },
  { idArea: 4, comment: "Reporting is manual and descriptive, not predictive." },
  { idArea: 4, comment: "Recruitment meets hiring targets but does not prevent downstream instability." },
  { idArea: 4, comment: "Recruitment operates in a productive but fragile state at approximately 51 percent maturity." },

];