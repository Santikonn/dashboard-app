export const rawMaturityData = [
  { area: "Quality", category: "Bonuses & Team Engagement", score: 90, summary: "Mechanism exists; linkage to sustained behavior change is limited." },
  { area: "Quality", category: "Calibration", score: 80, summary: "Strong discipline, but still manual and not analytically leveraged." },
  { area: "Quality", category: "Performance & Governance", score: 80, summary: "Governance intent exists, but execution is tool- and person-dependent." },
  { area: "Quality", category: "Root Cause Analysis", score: 79, summary: "Root Cause Analysis discussions exist but are not consistently data-backed or systematized." },
  { area: "Quality", category: "Feedback", score: 56, summary: "Feedback exists, but impact tracking and ownership are inconsistent. There is no team assignment for QA to be responsible for a group of interpreters and their coaching effectiveness." },
  { area: "Quality", category: "Monitoring", score: 40, summary: "Monitoring occurs, but coverage, planning, and repeatability are weak and largely informal." },
  { area: "Quality", category: "KPIs & Outlier Management", score: 33, summary: "Limited driver segmentation and weak repeatability prevent strategic targeting." },
  { area: "Quality", category: "Call Library", score: 20, summary: "Call listening sessions conducted regularly, discussing best practices and opportunity areas in a weekly basis with Ops, the call listening is mixing good and bad calls, however due to HIPAA compliance there is no call library recordings, however, is recommended to record role plays with the main challenges interactions to provide during training." },
  { area: "Training", category: "Curriculum, Content & Continuous Upskilling", score: 71, summary: "Strong execution foundation, largely supported by LMS and client content. Curriculum is well-structured for initial onboarding with LMS support and client-provided content. However, continuous upskilling post-graduation is reactive and ad hoc, without structured learning paths or refresher program. Business Implication: Interpreters may plateau or regress in performance without proactive development, and skill gaps only become visible when they manifest as quality or attrition issues." },
  { area: "Training", category: "Performance & Training Analytics", score: 70, summary: "Execution consistent but insights fragmented and not fully leveraged. Training tracks completion, attendance, and satisfaction consistently. However, learning effectiveness (knowledge retention, skill transfer) is not measured. Analytics are siloed and not surfaced to Operations in real-time. Business Implication: Training appears successful on process metrics, but true interpreter readiness at graduation is not validated -creating blind spots in production performance attribution." },
  { area: "Training", category: "Continuous Improvement", score: 33, summary: "Improvement exists but is reactive and not consistently closed loop. Improvement happens reactively-Typically in reponse to escalations or visible gaps. There is no closed-loop process to feed production performance data back into training design or content updates. Incentives programs exist but are not aligned to training milestones, readiness indicators, or sustained performance post-graduation. Bonus structures focus on tenure or volume rather than quality and compliance. Business Implication: Without a structure RCA and improvement process, the same readiness gaps repeat across waves, and training cannot evolve with changing demand patterns." },
  { area: "Training", category: "Nesting, Graduation & Transitions", score: 20, summary: "Nesting happens but without Training-owned structure, KPIS, QA Governance, ratio 1:5 from ops supervisors. Nesting is executed but not owned by Training end-to-end. There is no structured nesting framework with defined milestones, KPIS, or QA oversight. Graduation decisions are often made by Operations without formalized readiness criteria. Business Implication: Premature graduation leads to interpreters entering production underprepared-driving early attrition, quality issues, and increased coaching burden in operations." },
  { area: "Training", category: "Strategy and Governance", score: 20, summary: "Strategy exists conceptually but not wave-based or governed by Training. Currently defined at the program level, not differentiated by wave profile, language complexity, or interpreter risk. Governance is informal, with no standing Training review forum or cross-functional readiness alignment. Business Implication: Without wave-based strategy, Training cannot proactively shape readiness based on demand signals-leaving execution reactive and misaligned with workforce planning needs." },
  { area: "Workforce", category: "Interval Compliance", score: 50, summary: "IC is measured and reported, but without formal thresholds or a defined “day in target”" },
  { area: "Workforce", category: "Capacity Planning", score: 40, summary: "Assumptions exist but are not validated. Productivity gaps identify (7.8 vs 6.6) with no formal RCA" },
  { area: "Workforce", category: "Governance", score: 40, summary: "Governance forums exist, but no daily/intraday sync and no structured weekly RCA" },
  { area: "Workforce", category: "Scheduling", score: 40, summary: "Schedules operate, but no audits, no interval-based PTO slots, and no clear OT/PTO rules" },
  { area: "Workforce", category: "Real-Time Management", score: 30, summary: "Intraday management mostly manual; alerts and adherence visibility incomplete depending on platform." },
  { area: "Workforce", category: "Reporting & Insights", score: 30, summary: "Isolated reports; no standard heatmaps or interval-level risk visuals" },
  { area: "Workforce", category: "Tools", score: 30, summary: "Partial use of IEX/NICE (schedule uploads only). No end-to-end WFM or IC/RTA integration" },
  { area: "Workforce", category: "Contract Governance", score: 20, summary: "No forecast lock, allowed variability, or clear escalation rules." },
  { area: "Workforce", category: "Forecasting", score: 20, summary: "No documented methodology; no consolidated historical; forecast changes and trend breaks handled manually" },
  { area: "Workforce", category: "Shrinkage & ABS", score: 20, summary: "No formal taxonomy or interval-level drivers; visibility is aggregated" },
  { area: "Workforce", category: "Incentives", score: 10, summary: "No Incentives aligned to interval risk or adherence (nice to have)" },
  { area: "Recruitment", category: "ATS & Data Governance", score: 64, summary: "No single source of truth for recruitment data.Information is split across PeopleForce, multiple Excel trackers, TalentX files, and separate rosters, creating fragmentation and risk, Heavy dependency on Excel files with no formal data governance, version control, or access controls, exposing the operation to data loss, deletion, or manipulation risks.External recruitment vendor (TalentX/Telenix) does not use PeopleForce, forcing parallel tracking and manual reconciliation between systems. PeopleForce is not yet fully leveraged as an ATS/CRM for end-to-end recruitment analytics; key data still lives outside the platform. No systematic capture of city-level location data (only country), limiting geographic analysis and labor market insights Candidate language proficiency (Hallo) scores) is not integrated into PeopleForce, preventing correlation between language level, performance, attrition, and source quality. Daily and periodic reports are manually built, consuming leadership time that should be focused on strategy rather than reporting. Lack of automated dashboards for real-time visibility into pipeline health, source effectiveness, and hiring progress Recruitment analytics are descriptive at best, with no predictive or proactive insights enabled today (e.g., attrition risk by source orprofile)" },
  { area: "Recruitment", category: "Selection & Assessment Controls", score: 60, summary: "No formal, auditable process to ensure data consistency (date formats, fields, definitions) across recruiters and vendors" },
  { area: "Recruitment", category: "Sourcing Strategy & Channel Effectivenss", score: 58, summary: "Volume is visible; quality and ROI are not KPI framework is extremely limited; focus is primarily on fill rate, with minimal tracking of time-to-hire, recruiter productivity, funnel conversion, or quality-of-hire. Time-to-hire is not formally measured or trended, limiting capacity planning and SLA discussions with Operations. Conversion rates by sourcing channel exist but are not fully automated or consistently analyzed end-to-end (leads → hires → performance). No structured measurement of recruiter effectiveness (interviews per recruiter, pass-through rates, wave success rates). Marketing performance (cost, volume, and quality of leads by channel) is not tightly integrated into recruitment decision-making ." },
  { area: "Recruitment", category: "Demand Intake & Workforce Aligment", score: 50, summary: "Recruitment planning historically operated reactively via emails and ad-hoc requests rather than structured, recurring alignment with Workforce Management (WFM). Recruitment–WFM integration is still maturing and not yet embedded as a disciplined weekly planning and forecasting process." },
  { area: "Recruitment", category: "Vendor (External Recuiter Governance)", score: 50, summary: "Dependency exceeds governance. There is gaps in the process, communication G expectations" },
  { area: "Recruitment", category: "Reporting % Predictive Capability", score: 40, summary: "Requisitions are managed as “evergreen” rather than per wave or per role, making root- cause analysis by hiring batch, recruiter, or job profile nearly impossible. No standardized requisition ID structure that allows tracking hiring outcomes by wave, recruiter, or sourcing channel." },
  { area: "Recruitment", category: "Cross-Functional Feedback Loops", score: 33, summary: "Recruitment does not consistently participate in training kickoffs or early-tenure feedback loops (e.g., structured focus groups with new hires) as a standard practice. Limited formal feedback loop between Operations performance issues and upstream recruitment criteria (profiles, sourcing strategies, screening thresholds). oot-cause analysis for attrition or low performance is difficult due to missing links between recruitment data, training outcomes, and operational KPIs" },
];